# Medical Sentiment Analysis

A production-ready medical sentiment analysis system using transformer-based models for personalized emotion detection in Polish and English healthcare texts.

## üéØ Project Status: Production Ready

- **Overall F1-Score**: 72.18% (XLM-RoBERTa weighted)
- **Production Emotions**: 13/18 emotions achieve F1 > 60%
- **Exceptional Performance**: 7/18 emotions achieve F1 > 80%
- **Languages**: Polish & English support
- **Deployment**: Clinical application ready

## üöÄ Quick Start

### Prerequisites
- Python ‚â•3.10
- CUDA-capable GPU (recommended)
- 16GB+ RAM

### Installation
```bash
# Clone repository
git clone <repository-url>
cd medical_sentiment_analysis

# Install dependencies
uv sync

# Prepare data and build views
make prepare-data
make build-enc-view
```

### Production Model Usage
```bash
# Use the best performing model (XLM-RoBERTa weighted)
CHECKPOINT=artifacts/models/encoder/enc_baseline_xlmr_weighted make eval-enc-test
```

## üìä Performance Summary

### Model Comparison
| Model | F1-Score | Status | Recommended Use |
|-------|----------|--------|-----------------|
| **XLM-RoBERTa (Weighted)** | **72.18%** | ‚úÖ Production | Clinical deployment |
| XLM-RoBERTa (Non-weighted) | 33.74% | ‚ùå Research | Baseline comparison |
| mDeBERTa (Weighted) | 43.61% | ‚ö†Ô∏è Development | Further optimization |
| mDeBERTa (Non-weighted) | 11.54% | ‚ùå Research | Baseline comparison |

### Emotion Categories (XLM-RoBERTa Weighted)

**üéØ Tier 1 - Exceptional (F1 > 80%)**
- funny (96.9%), compassion (90.1%), ironic (89.5%), understandable (84.6%), interesting (83.1%), anger (80.7%)

**‚úÖ Tier 2 - Production Ready (F1 60-80%)**  
- political (79.0%), negative (76.3%), fear (73.6%), surprise (74.3%), sadness (72.2%), offensive (69.8%), disgust (69.4%)

**‚ö†Ô∏è Tier 3 - Development Focus (F1 < 60%)**
- positive (52.2%), happiness (59.6%), inspiring (46.1%), delight (37.6%), calm (35.5%)

## üèóÔ∏è Architecture

### Model Pipeline
```
Medical Text ‚Üí Language Detection ‚Üí Persona Assignment ‚Üí 
Tokenization ‚Üí XLM-RoBERTa ‚Üí Mean Pooling ‚Üí 
Linear Head ‚Üí Binary Classification (18 emotions)
```

### Key Components
- **EncoderClassifier**: Transformer + mean pooling + binary classification head
- **Weighted Loss**: BCEWithLogitsLoss with class-specific weights (0.774-5.451√ó)
- **Threshold Optimization**: Emotion-specific decision boundaries
- **Persona Integration**: 16 healthcare personas for personalization

## üìÅ Project Structure

```
medical_sentiment_analysis/
‚îú‚îÄ‚îÄ configs/           # YAML configurations
‚îú‚îÄ‚îÄ modules/           # Core Python modules
‚îú‚îÄ‚îÄ scripts/           # Training & evaluation scripts
‚îú‚îÄ‚îÄ artifacts/         # Model checkpoints & results
‚îú‚îÄ‚îÄ data/             # Processed datasets
‚îú‚îÄ‚îÄ reports/          # Analysis & evaluation reports
‚îú‚îÄ‚îÄ archive/          # Deprecated files
‚îî‚îÄ‚îÄ schema/           # Data validation schemas
```

## üîß Development Commands

### Training
```bash
# Train production model
make train-enc-baseline-weighted

# Train with persona tokens
make train-enc-persona-token-xlmr
make train-enc-persona-token-mdeberta
```

### Evaluation
```bash
# Evaluate on test set
make eval-enc-test CHECKPOINT=artifacts/models/encoder/model_name

# Run threshold optimization
python scripts/optimize_thresholds.py

# Generate calibration analysis
make calib-enc CHECKPOINT=artifacts/models/encoder/model_name
```

### Analysis
```bash
# Class imbalance analysis
python scripts/analyze_class_imbalance.py

# Model comparison
python scripts/compare_models.py

# Training visualization
python scripts/visualize_training.py
```

## üìà Technical Achievements

### Class Imbalance Solution
- **Problem**: Severe class imbalance (up to 9.74:1 ratios)
- **Solution**: Weighted BCE loss with balanced class weights
- **Result**: +2,680% average F1-score improvement

### Language Detection Enhancement
- **Fixed**: Weak heuristic misclassifying English as Polish
- **Improved**: Expanded vocabulary + pattern detection
- **Result**: Accurate 730 Polish / 9,290 English distribution

### Threshold Optimization
- **Per-emotion thresholds**: Optimized decision boundaries
- **Strategies**: Aggressive (0.22-0.24), Conservative (0.65-0.87), Balanced (0.31-0.50)
- **Impact**: +3-5% F1-score improvements

## üè• Clinical Applications

### Deployment Tiers
- **High-Stakes**: Use only F1 > 80% emotions (7 emotions)
- **Standard**: Deploy F1 > 60% emotions (13 emotions)  
- **Research**: Monitor all 18 emotions with tracking

### Healthcare Personas
16 specialized personas including:
- Patient types (young_mother, senior_patient, health_anxiety_patient)
- Providers (supervising_physician, clinic_manager)
- Specialists (mental_health_advocate, healthcare_journalist)

## üìã Requirements

### System Requirements
- GPU: 8GB+ VRAM for training, 4GB+ for inference
- RAM: 16GB+ recommended
- Storage: 10GB+ for full artifacts

### Dependencies
- transformers ‚â•4.21.0
- torch ‚â•1.12.0
- scikit-learn ‚â•1.1.0
- pandas ‚â•1.4.0
- numpy ‚â•1.21.0

## üîç Monitoring & Maintenance

### Performance Monitoring
Monitor these metrics in production:
- Per-emotion F1-scores
- Language detection accuracy  
- Persona assignment consistency
- Threshold calibration drift

### Retraining Triggers
- F1-score drops below 60% for Tier 2 emotions
- New medical terminology emergence
- Language distribution changes
- Class imbalance shifts

## üìä Reports & Documentation

Detailed analysis available in:
- `reports/per_label_analysis_weighted_vs_nonweighted.md`
- `reports/xlmr_vs_mdeberta_comparison_report.md`
- `reports/mdeberta_v3_base_persona_token_evaluation_report.md`

## üìú License

This project is for medical research and clinical applications. Please ensure compliance with healthcare data regulations (HIPAA, GDPR) when deploying.

## ü§ù Contributing

1. Fork the repository
2. Create feature branch
3. Run full test suite: `make preview-base && make preview-enc`
4. Submit pull request with performance benchmarks

---

**Last Updated**: 2025-08-29  
**Model Version**: XLM-RoBERTa Weighted v1.0  
**Performance**: 72.18% F1-Score (Production Ready)