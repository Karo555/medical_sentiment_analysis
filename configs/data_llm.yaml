# configs/data_llm.yaml
# Konfiguracja WIDOKU DANYCH dla LLM (tryb generacyjny: input_text -> target_text w JSON).
# Ten plik opisuje:
# - jakie pola źródłowe są wymagane,
# - jak budować prompt (różne warianty personalizacji),
# - jak serializować i walidować target (JSON z 21 liczbami 0–1),
# - filtrowanie, balansowanie, ścieżki wejścia/wyjścia.

version: 1
name: llm_data_view
description: >
  Dane do fine-tuningu LLM w schemacie input->output.
  input_text to pełny prompt z instrukcją, personą (opcjonalnie) i językiem,
  target_text to dokładny JSON z wektorem 21 wartości [0,1].

# ---------------------------------------------------------------------------
# ŚCIEŻKI I PLIKI
# ---------------------------------------------------------------------------
paths:
  raw_dir: data/raw                    # źródła „prawdy” (opinie, persony)
  processed_dir: data/processed        # dane po preprocessingu
  view_dir: data/processed/llm         # materializacja widoku LLM (input_text/target_text)
  reports_dir: reports/llm             # raporty walidacji
  personas_file: data/personas/personas.json      # kanoniczny słownik person (opcjonalny)
  label_names_file: schema/label_names.json       # lista 21 nazw etykiet (kolejność)

files:
  train: train.jsonl
  val: val.jsonl
  test: test.jsonl

# Jeśli używamy gotowych splitów zewnętrznych (zalecane):
external_splits:
  enabled: true
  dir: data/splits
  train: train_ids.csv        # kolumna: id
  val: val_ids.csv
  test: test_ids.csv

# ---------------------------------------------------------------------------
# KONTRAKT ŹRÓDŁOWEGO REKORDU (po preprocessingu „base”)
# ---------------------------------------------------------------------------
source_record_contract:
  required_fields:
    - id
    - text
    - persona_id
    - persona_desc
    - lang
    - labels
  field_types:
    id: string
    text: string
    persona_id: string
    persona_desc: string
    lang: string         # 'pl' lub 'en'
    labels: array[float] # długość = 21
  constraints:
    lang_allowed: ["pl", "en"]
    labels_length: 21
    labels_range: [0.0, 1.0]
    persona_id_pattern: "^[a-z0-9_\\-]+$"
  on_missing:
    policy: drop_with_report   # dropuje rekord i loguje do raportu
  on_out_of_range:
    policy: clamp_and_report   # klamruje do [0,1] i loguje

# ---------------------------------------------------------------------------
# BUDOWANIE PROMPTU (input_text)
# ---------------------------------------------------------------------------
prompt:
  # Definicje tokenów/specjalnych znaczników. LLM zwykle nie wymagają rejestracji,
  # ale trzymamy spójny format z encoderami.
  tokens:
    lang_tag_format: "<lang={lang}>"            # np. <lang=pl>
    persona_token_format: "<p:{persona_id}>"    # np. <p:young_mother>
    persona_block:
      start: "<persona>"
      end: "</persona>"

  # Globalne ustawienia składania promptu
  global:
    include_trailing_newline: true
    normalize_whitespace: true
    strip_input_text: true
    max_total_chars: 6000          # twardy limit bezpieczeństwa, zanim przetniemy
    truncate_strategy: "end"       # "start" | "end"
    add_system_prefix: true        # doda nagłówek z instrukcją w polu 'system_prefix'

  # Instrukcje bazowe (możesz edytować style)
  system_prefix: |
    Instrukcja: Na podstawie TEKSTU opinii i informacji o osobie (jeśli podano) przewidź 21 wartości w zakresie 0–1.
    Zwróć odpowiedź w DOKŁADNYM formacie JSON:
    {"labels": [f1, f2, ..., f21]}
    Gdzie f_i są liczbami z zakresu [0,1]. Nie dodawaj komentarzy ani tekstu poza JSON.

  # Tryby personalizacji budujące input_text.
  # Zmienna {text} to treść opinii, {lang} to "pl"|"en",
  # {persona_id}, {persona_desc} jak w rekordzie źródłowym.
  modes:
    # 1) Brak personalizacji (ignorujemy personę)
    non_personalized: |
      {system_prefix}
      {lang_tag}
      Tekst: {text}

    # 2) Personalizacja opisem persony (semantyka)
    personalized_desc: |
      {system_prefix}
      {lang_tag}
      {persona_block_start}
      {persona_desc}
      {persona_block_end}
      Tekst: {text}

    # 3) Specjalny token persony (opcjonalnie bez opisu)
    persona_token: |
      {system_prefix}
      {persona_token} {lang_tag}
      Tekst: {text}

    # 4) Personalized instruction – instrukcja parametryzowana cechami persony
    personalized_instruction: |
      Instrukcja: Jako system oceny emocji uwzględnij profil osoby i jej wrażliwości.
      Oceń TEKST w 21 wymiarach (0–1) i zwróć TYLKO JSON:
      {"labels": [f1, f2, ..., f21]}
      Profil osoby:
      {persona_desc}
      {lang_tag}
      Tekst: {text}

  # Parametry zastępowania znaczników
  render:
    include_lang_tag: true
    include_persona_token_in_modes: ["persona_token"]  # gdzie wstrzykujemy {persona_token}
    include_persona_desc_in_modes: ["personalized_desc", "personalized_instruction"]
    collapse_empty_lines: true

# ---------------------------------------------------------------------------
# TARGET (output_text) – JSON z 21 wartościami
# ---------------------------------------------------------------------------
target:
  json:
    key: "labels"
    length: 21
    float_precision: 3          # przy przygotowaniu target_text formatuj do n miejsc
    ensure_ascii: false
    separators: [",", ":"]      # jak w json.dumps(separators=(",", ":"))
    allow_whitespace: false     # jeśli true, zezwól na spacje/nowe linie (zwykle false)
    sorted_keys: false
  validation:
    # JSON Schema do walidacji target_text (parafraza; walidator sprawdza długość i zakres)
    schema: |
      {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "type": "object",
        "required": ["labels"],
        "properties": {
          "labels": {
            "type": "array",
            "minItems": 21,
            "maxItems": 21,
            "items": {
              "type": "number",
              "minimum": 0.0,
              "maximum": 1.0
            }
          }
        },
        "additionalProperties": false
      }
    # Jeżeli model wygeneruje niepoprawny JSON:
    on_invalid_json: "attempt_fix_then_drop"   # "attempt_fix_then_drop" | "drop" | "keep_and_flag"
    fixup:
      # Proste poprawki zanim odrzucimy: usunięcie trailing tekstu, naprawy przecinków itd.
      truncate_after_last_bracket: true
      replace_single_quotes: true
      remove_trailing_commas: true
      coerce_non_numbers_to_float: 0.0
      clamp_values_to_range: [0.0, 1.0]
      pad_or_trim_to_length: 21
  # Generacja target_text (gold) podczas budowy widoku z rekordów źródłowych
  build_from_labels:
    enabled: true
    number_format: "fixed"       # "fixed" => zaokrąglanie do float_precision
    float_precision: 3
    ensure_sorted_order_by_label_names_file: true

# ---------------------------------------------------------------------------
# FILTRY I SANITY CHECK
# ---------------------------------------------------------------------------
filters:
  text_min_chars: 5
  text_max_chars: 4000
  drop_if_missing_persona_desc_in_modes: ["personalized_desc", "personalized_instruction"]
  deduplication:
    enabled: true
    scope: "within-split"     # "global" | "within-split"
    key: "text"               # deduplikujemy po tekście (po normalizacji)
    normalization:
      lower: true
      strip: true
      collapse_spaces: true

# ---------------------------------------------------------------------------
# BALANSOWANIE / SAMPLING
# ---------------------------------------------------------------------------
balancing:
  enabled: true
  by_lang:
    target_dist:
      pl: 0.5
      en: 0.5
    strategy: "reweight"      # "reweight" | "undersample" | "oversample" | "none"
    tolerance: 0.05
  by_persona:
    min_per_persona: 50
    max_per_persona: 5000
    strategy: "clip_and_reweight"  # soft ograniczenia + wagi w samplerze

# ---------------------------------------------------------------------------
# MATERALIZACJA WIDOKU I KOLUMN
# ---------------------------------------------------------------------------
materialization:
  output_format: "jsonl"
  output_columns:
    - id
    - input_text
    - target_text
  write_mode: "overwrite"   # "overwrite" | "append"
  shard_size: 100000        # rekordów na plik przy dużych zbiorach (opcjonalnie)
  write_reports:
    schema_violations: true
    fixups_applied: true
    class_balance: true

# ---------------------------------------------------------------------------
# POWIĄZANIA ZE SPLITAMI
# ---------------------------------------------------------------------------
splits:
  use_external: true
  if_external_missing_fallback: "random"   # "error" | "random"
  random_seed: 1337
  random_ratios:
    train: 0.8
    val: 0.1
    test: 0.1
  stratify_by: ["lang", "persona_id"]

# ---------------------------------------------------------------------------
# AUGMENTACJE (opcjonalne – domyślnie wyłączone)
# ---------------------------------------------------------------------------
augmentation:
  enabled: false
  methods:
    backtranslation:
      enabled: false
      langs: ["pl", "en"]
      probability: 0.1
    paraphrase:
      enabled: false
      probability: 0.1
  apply_to:
    text: true
    persona_desc: false   # zwykle nie modyfikujemy opisów person

# ---------------------------------------------------------------------------
# LOGOWANIE I REPRODUKCJA
# ---------------------------------------------------------------------------
logging:
  level: "INFO"
  preview_n_examples_per_split: 3
  save_preview_to: "reports/llm/preview_examples.jsonl"

reproducibility:
  seed: 1337
  deterministic_ops: true
